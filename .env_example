# Set your values and copy to .env file to be used by load_dotenv()

# Ollama configuration
# Base URL for the local Ollama daemon (default host + port shown)
OLLAMA_BASE_URL="http://127.0.0.1:11434"
# Comma-separated list of models exposed through the chat UI
OLLAMA_MODELS="qwen3:4b-instruct-2507-fp16"
# Default model selected when the UI loads (must appear in OLLAMA_MODELS)
OLLAMA_DEFAULT_MODEL="qwen3:4b-instruct-2507-fp16"
# Embedding model served by Ollama for Chroma queries
OLLAMA_EMBED_MODEL="nomic-embed-text"

# Both HTTPS origins for production
ALLOWED_ORIGINS=https://chat.alexlabs.net,https://www.chat.alexlabs.net

# Host header validation (no scheme, just domain/IP)
ALLOWED_HOSTS=chat.alexlabs.net,www.chat.alexlabs.net,localhost,127.0.0.1

# User database - format: username:password,username:password
# for example:
USERS_DB=admin:12345, user01:kuku, user02:dummy

